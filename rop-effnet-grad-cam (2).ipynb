{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12b9981",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-12T13:28:31.127913Z",
     "iopub.status.busy": "2024-09-12T13:28:31.127577Z",
     "iopub.status.idle": "2024-09-12T13:29:19.753392Z",
     "shell.execute_reply": "2024-09-12T13:29:19.752412Z"
    },
    "papermill": {
     "duration": 48.639464,
     "end_time": "2024-09-12T13:29:19.755989",
     "exception": false,
     "start_time": "2024-09-12T13:28:31.116525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grad-cam\r\n",
      "  Downloading grad-cam-1.5.3.tar.gz (7.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from grad-cam) (9.5.0)\r\n",
      "Requirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (0.19.0)\r\n",
      "Collecting ttach (from grad-cam)\r\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.66.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.10.0.84)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from grad-cam) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.2.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (2024.6.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (2.9.0.post0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.14.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\r\n",
      "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\r\n",
      "Building wheels for collected packages: grad-cam\r\n",
      "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.3-py3-none-any.whl size=38657 sha256=b919e99097397d442d060b38b2aadaec6f1a05c4b79b846b29b5e4b4f1d0f773\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/ce/70/fe64f851895eae830b3c63ec7fc464cfa7c81aeb7ad4f68063\r\n",
      "Successfully built grad-cam\r\n",
      "Installing collected packages: ttach, grad-cam\r\n",
      "Successfully installed grad-cam-1.5.3 ttach-0.0.3\r\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "#from google.colab import drive\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import shutil\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from collections import defaultdict\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "#from pytorch_grad_cam import GradCAM\n",
    "#from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import pickle\n",
    "\n",
    "!pip install grad-cam\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdcd297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:19.781114Z",
     "iopub.status.busy": "2024-09-12T13:29:19.780095Z",
     "iopub.status.idle": "2024-09-12T13:29:19.797422Z",
     "shell.execute_reply": "2024-09-12T13:29:19.796717Z"
    },
    "papermill": {
     "duration": 0.031814,
     "end_time": "2024-09-12T13:29:19.799511",
     "exception": false,
     "start_time": "2024-09-12T13:29:19.767697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MEAN = torch.tensor((0.485, 0.456, 0.406))\n",
    "STD  = torch.tensor((0.229, 0.224, 0.225))\n",
    "# BATCH_SIZE = 64\n",
    "NUM_CLASSES = 2 # Healthy & Not Healthy\n",
    "TRAIN_DATA_PATH = \"/kaggle/input/binary-coco-first-article/train\"\n",
    "TEST_DATA_PATH = \"/kaggle/input/binary-coco-first-article/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae39692e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:19.823125Z",
     "iopub.status.busy": "2024-09-12T13:29:19.822714Z",
     "iopub.status.idle": "2024-09-12T13:29:19.828794Z",
     "shell.execute_reply": "2024-09-12T13:29:19.827838Z"
    },
    "papermill": {
     "duration": 0.020028,
     "end_time": "2024-09-12T13:29:19.830859",
     "exception": false,
     "start_time": "2024-09-12T13:29:19.810831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EfficientNetB1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB1, self).__init__()\n",
    "        self.effnet = models.efficientnet_b1(pretrained=True)\n",
    "        num_ftrs = self.effnet.classifier[1].in_features\n",
    "        self.effnet.classifier[1].fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.effnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce4c530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:19.854674Z",
     "iopub.status.busy": "2024-09-12T13:29:19.854406Z",
     "iopub.status.idle": "2024-09-12T13:29:19.936463Z",
     "shell.execute_reply": "2024-09-12T13:29:19.935596Z"
    },
    "papermill": {
     "duration": 0.096354,
     "end_time": "2024-09-12T13:29:19.938582",
     "exception": false,
     "start_time": "2024-09-12T13:29:19.842228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5245e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:19.963118Z",
     "iopub.status.busy": "2024-09-12T13:29:19.962748Z",
     "iopub.status.idle": "2024-09-12T13:29:20.822579Z",
     "shell.execute_reply": "2024-09-12T13:29:20.821743Z"
    },
    "papermill": {
     "duration": 0.874447,
     "end_time": "2024-09-12T13:29:20.824932",
     "exception": false,
     "start_time": "2024-09-12T13:29:19.950485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n",
      "100%|██████████| 30.1M/30.1M [00:00<00:00, 121MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define model and criterion\n",
    "model = EfficientNetB1(NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da475cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:20.850462Z",
     "iopub.status.busy": "2024-09-12T13:29:20.850140Z",
     "iopub.status.idle": "2024-09-12T13:29:21.385416Z",
     "shell.execute_reply": "2024-09-12T13:29:21.384490Z"
    },
    "papermill": {
     "duration": 0.550441,
     "end_time": "2024-09-12T13:29:21.387628",
     "exception": false,
     "start_time": "2024-09-12T13:29:20.837187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/260028967.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/effnet-updated-unhealthy/pytorch/default/1/effnet_weights (2).pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/kaggle/input/effnet-updated-unhealthy/pytorch/default/1/effnet_weights (2).pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6a9698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.414387Z",
     "iopub.status.busy": "2024-09-12T13:29:21.414057Z",
     "iopub.status.idle": "2024-09-12T13:29:21.419492Z",
     "shell.execute_reply": "2024-09-12T13:29:21.418582Z"
    },
    "papermill": {
     "duration": 0.021224,
     "end_time": "2024-09-12T13:29:21.421504",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.400280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "def custom_loader(path):\n",
    "    return datasets.folder.default_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413d8568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.448256Z",
     "iopub.status.busy": "2024-09-12T13:29:21.447961Z",
     "iopub.status.idle": "2024-09-12T13:29:21.453498Z",
     "shell.execute_reply": "2024-09-12T13:29:21.452687Z"
    },
    "papermill": {
     "duration": 0.021087,
     "end_time": "2024-09-12T13:29:21.455453",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.434366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# incorrect_predictions = []\n",
    "# dataset_directory = Path(\"/kaggle/input/corner-cases/corner_cases\")\n",
    "# test_dataset = datasets.ImageFolder(root=dataset_directory, transform=TRANSFORM_IMG, loader=custom_loader)\n",
    "\n",
    "# class_names = test_dataset.classes\n",
    "# device = 'cuda'\n",
    "# num_images_to_show = 10\n",
    "# num_cols = 3\n",
    "# for i in range(len(test_dataset)):\n",
    "#     input_data, true_label = test_dataset[i]\n",
    "#     input_data = input_data.unsqueeze(0).to(device)\n",
    "\n",
    "#     output = model(input_data)\n",
    "#     _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "#     if predicted_label != true_label:\n",
    "#         incorrect_predictions.append((input_data, true_label, predicted_label.item()))\n",
    "\n",
    "#     if len(incorrect_predictions) >= num_images_to_show:\n",
    "#         break\n",
    "\n",
    "# # num_rows = (len(incorrect_predictions) + num_cols - 1) // num_cols\n",
    "\n",
    "# # fig, axs = plt.subplots(num_rows, num_cols, figsize=(25, num_rows * 3))\n",
    "\n",
    "# for i, (input_data, true_label, predicted_label) in enumerate(incorrect_predictions):\n",
    "#     title_color = 'red'\n",
    "#     img = input_data.squeeze().cpu().numpy().transpose(1, 2, 0) / 2 + 0.5\n",
    "#     true_label_name = class_names[true_label]\n",
    "#     predicted_label_name = class_names[predicted_label]\n",
    "\n",
    "# #     if num_rows == 1:\n",
    "# #         axs[i % num_cols].imshow(img)\n",
    "# #         axs[i % num_cols].set_title(f'Truth: {true_label_name}\\nPredicted: {predicted_label_name}', color=title_color)\n",
    "# #         axs[i % num_cols].axis('off')\n",
    "# #     else:\n",
    "# #         row_idx = i // num_cols\n",
    "# #         col_idx = i % num_cols\n",
    "# #         axs[row_idx, col_idx].imshow(img)\n",
    "# #         axs[row_idx, col_idx].set_title(f'Truth: {true_label_name}\\nPredicted: {predicted_label_name}', color=title_color)\n",
    "# #         axs[row_idx, col_idx].axis('off')\n",
    "\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3abe9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.481046Z",
     "iopub.status.busy": "2024-09-12T13:29:21.480700Z",
     "iopub.status.idle": "2024-09-12T13:29:21.487313Z",
     "shell.execute_reply": "2024-09-12T13:29:21.486469Z"
    },
    "papermill": {
     "duration": 0.02117,
     "end_time": "2024-09-12T13:29:21.489177",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.468007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preprocess = TRANSFORM_IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a958eced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.514293Z",
     "iopub.status.busy": "2024-09-12T13:29:21.513609Z",
     "iopub.status.idle": "2024-09-12T13:29:21.517218Z",
     "shell.execute_reply": "2024-09-12T13:29:21.516418Z"
    },
    "papermill": {
     "duration": 0.018214,
     "end_time": "2024-09-12T13:29:21.519124",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.500910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(test_dataset)):\n",
    "#     print(test_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66664583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.544424Z",
     "iopub.status.busy": "2024-09-12T13:29:21.544127Z",
     "iopub.status.idle": "2024-09-12T13:29:21.548189Z",
     "shell.execute_reply": "2024-09-12T13:29:21.547275Z"
    },
    "papermill": {
     "duration": 0.019182,
     "end_time": "2024-09-12T13:29:21.550069",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.530887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(test_dataset)):\n",
    "#     output = model(test_dataset[i][0].unsqueeze(0).to(device))\n",
    "#     _, predicted_label = torch.max(output, 1)\n",
    "#     if int(predicted_label[0]) == 0:\n",
    "#         label = \"healthy\"\n",
    "#     else:\n",
    "#         label = \"unhealthy\"\n",
    "#     print(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9294b2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.578344Z",
     "iopub.status.busy": "2024-09-12T13:29:21.577955Z",
     "iopub.status.idle": "2024-09-12T13:29:21.585688Z",
     "shell.execute_reply": "2024-09-12T13:29:21.584565Z"
    },
    "papermill": {
     "duration": 0.026328,
     "end_time": "2024-09-12T13:29:21.588296",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.561968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.effnet.features[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d647023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.624483Z",
     "iopub.status.busy": "2024-09-12T13:29:21.623972Z",
     "iopub.status.idle": "2024-09-12T13:29:21.631957Z",
     "shell.execute_reply": "2024-09-12T13:29:21.630987Z"
    },
    "papermill": {
     "duration": 0.02885,
     "end_time": "2024-09-12T13:29:21.634692",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.605842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.effnet.features[7][0].block[-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868e455",
   "metadata": {
    "papermill": {
     "duration": 0.012079,
     "end_time": "2024-09-12T13:29:21.661440",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.649361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80234d",
   "metadata": {
    "papermill": {
     "duration": 0.012236,
     "end_time": "2024-09-12T13:29:21.685862",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.673626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8702268d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.713686Z",
     "iopub.status.busy": "2024-09-12T13:29:21.713332Z",
     "iopub.status.idle": "2024-09-12T13:29:21.725468Z",
     "shell.execute_reply": "2024-09-12T13:29:21.724483Z"
    },
    "papermill": {
     "duration": 0.02891,
     "end_time": "2024-09-12T13:29:21.727692",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.698782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/test-3/desease(looks_healthy)/\"\n",
    "save_path = \"/kaggle/working/gradcam/test-3/desease(looks_healthy)/\"\n",
    "\n",
    "# Unhealthy\n",
    "original_label = \"Unhealthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb19752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:21.754792Z",
     "iopub.status.busy": "2024-09-12T13:29:21.754097Z",
     "iopub.status.idle": "2024-09-12T13:29:29.138971Z",
     "shell.execute_reply": "2024-09-12T13:29:29.137848Z"
    },
    "papermill": {
     "duration": 7.40083,
     "end_time": "2024-09-12T13:29:29.141546",
     "exception": false,
     "start_time": "2024-09-12T13:29:21.740716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "648bb5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:29.169287Z",
     "iopub.status.busy": "2024-09-12T13:29:29.168932Z",
     "iopub.status.idle": "2024-09-12T13:29:29.179532Z",
     "shell.execute_reply": "2024-09-12T13:29:29.178802Z"
    },
    "papermill": {
     "duration": 0.025702,
     "end_time": "2024-09-12T13:29:29.181389",
     "exception": false,
     "start_time": "2024-09-12T13:29:29.155687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/test-3/desease(looks_unhealthy)/\"\n",
    "save_path = \"/kaggle/working/gradcam/test-3/desease(looks_unhealthy)/\"\n",
    "\n",
    "# Unhealthy\n",
    "original_label = \"Unhealthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97548ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:29.207574Z",
     "iopub.status.busy": "2024-09-12T13:29:29.207265Z",
     "iopub.status.idle": "2024-09-12T13:29:36.480325Z",
     "shell.execute_reply": "2024-09-12T13:29:36.479384Z"
    },
    "papermill": {
     "duration": 7.288775,
     "end_time": "2024-09-12T13:29:36.482826",
     "exception": false,
     "start_time": "2024-09-12T13:29:29.194051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d68232",
   "metadata": {
    "papermill": {
     "duration": 0.01367,
     "end_time": "2024-09-12T13:29:36.510888",
     "exception": false,
     "start_time": "2024-09-12T13:29:36.497218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb2189ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:36.538551Z",
     "iopub.status.busy": "2024-09-12T13:29:36.538186Z",
     "iopub.status.idle": "2024-09-12T13:29:36.549484Z",
     "shell.execute_reply": "2024-09-12T13:29:36.548489Z"
    },
    "papermill": {
     "duration": 0.027467,
     "end_time": "2024-09-12T13:29:36.551474",
     "exception": false,
     "start_time": "2024-09-12T13:29:36.524007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/test-3/normal(looks_healthy)/\"\n",
    "save_path = \"/kaggle/working/gradcam/test-3/normal(looks_healthy)/\"\n",
    "\n",
    "# Healthy\n",
    "original_label = \"Healthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0808e7e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:36.579070Z",
     "iopub.status.busy": "2024-09-12T13:29:36.578710Z",
     "iopub.status.idle": "2024-09-12T13:29:45.255938Z",
     "shell.execute_reply": "2024-09-12T13:29:45.255084Z"
    },
    "papermill": {
     "duration": 8.694061,
     "end_time": "2024-09-12T13:29:45.258558",
     "exception": false,
     "start_time": "2024-09-12T13:29:36.564497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7761ddd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:45.286415Z",
     "iopub.status.busy": "2024-09-12T13:29:45.286031Z",
     "iopub.status.idle": "2024-09-12T13:29:45.296878Z",
     "shell.execute_reply": "2024-09-12T13:29:45.296151Z"
    },
    "papermill": {
     "duration": 0.027013,
     "end_time": "2024-09-12T13:29:45.298836",
     "exception": false,
     "start_time": "2024-09-12T13:29:45.271823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/test-3/normal(looks_unhealthy)/\"\n",
    "save_path = \"/kaggle/working/gradcam/test-3/normal(looks_unhealthy)/\"\n",
    "\n",
    "# Healthy\n",
    "original_label = \"Healthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d85fa7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:45.326789Z",
     "iopub.status.busy": "2024-09-12T13:29:45.326463Z",
     "iopub.status.idle": "2024-09-12T13:29:56.787070Z",
     "shell.execute_reply": "2024-09-12T13:29:56.785895Z"
    },
    "papermill": {
     "duration": 11.477028,
     "end_time": "2024-09-12T13:29:56.789525",
     "exception": false,
     "start_time": "2024-09-12T13:29:45.312497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904196a",
   "metadata": {
    "papermill": {
     "duration": 0.014325,
     "end_time": "2024-09-12T13:29:56.817647",
     "exception": false,
     "start_time": "2024-09-12T13:29:56.803322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# binary-coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f41e096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:56.847208Z",
     "iopub.status.busy": "2024-09-12T13:29:56.846215Z",
     "iopub.status.idle": "2024-09-12T13:29:56.869437Z",
     "shell.execute_reply": "2024-09-12T13:29:56.868693Z"
    },
    "papermill": {
     "duration": 0.040062,
     "end_time": "2024-09-12T13:29:56.871382",
     "exception": false,
     "start_time": "2024-09-12T13:29:56.831320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/binary-coco-first-article/test/healthy/\"\n",
    "save_path = \"/kaggle/working/gradcam/binary-coco-first-article/test/healthy/\"\n",
    "\n",
    "# Healthy\n",
    "original_label = \"Healthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f964f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:29:56.897972Z",
     "iopub.status.busy": "2024-09-12T13:29:56.897677Z",
     "iopub.status.idle": "2024-09-12T13:30:26.782956Z",
     "shell.execute_reply": "2024-09-12T13:30:26.782098Z"
    },
    "papermill": {
     "duration": 29.901424,
     "end_time": "2024-09-12T13:30:26.785579",
     "exception": false,
     "start_time": "2024-09-12T13:29:56.884155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b76617b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:30:26.814845Z",
     "iopub.status.busy": "2024-09-12T13:30:26.814216Z",
     "iopub.status.idle": "2024-09-12T13:30:26.828954Z",
     "shell.execute_reply": "2024-09-12T13:30:26.828118Z"
    },
    "papermill": {
     "duration": 0.030816,
     "end_time": "2024-09-12T13:30:26.830918",
     "exception": false,
     "start_time": "2024-09-12T13:30:26.800102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/binary-coco-first-article/test/unhealthy/\"\n",
    "save_path = \"/kaggle/working/gradcam/binary-coco-first-article/test/unhealthy/\"\n",
    "\n",
    "# Unhealthy\n",
    "original_label = \"Unhealthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e4247c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:30:26.858156Z",
     "iopub.status.busy": "2024-09-12T13:30:26.857813Z",
     "iopub.status.idle": "2024-09-12T13:31:18.221480Z",
     "shell.execute_reply": "2024-09-12T13:31:18.220639Z"
    },
    "papermill": {
     "duration": 51.380424,
     "end_time": "2024-09-12T13:31:18.223830",
     "exception": false,
     "start_time": "2024-09-12T13:30:26.843406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2b380",
   "metadata": {
    "papermill": {
     "duration": 0.012285,
     "end_time": "2024-09-12T13:31:18.249117",
     "exception": false,
     "start_time": "2024-09-12T13:31:18.236832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# corner-cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bec841c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:31:18.275162Z",
     "iopub.status.busy": "2024-09-12T13:31:18.274809Z",
     "iopub.status.idle": "2024-09-12T13:31:18.288406Z",
     "shell.execute_reply": "2024-09-12T13:31:18.287561Z"
    },
    "papermill": {
     "duration": 0.028986,
     "end_time": "2024-09-12T13:31:18.290432",
     "exception": false,
     "start_time": "2024-09-12T13:31:18.261446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/corner-cases/corner_cases/healthy/\"\n",
    "save_path = \"/kaggle/working/gradcam/corner_cases/healthy/\"\n",
    "\n",
    "# Healthy\n",
    "original_label = \"Healthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60295a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:31:18.316310Z",
     "iopub.status.busy": "2024-09-12T13:31:18.315972Z",
     "iopub.status.idle": "2024-09-12T13:31:24.256561Z",
     "shell.execute_reply": "2024-09-12T13:31:24.255613Z"
    },
    "papermill": {
     "duration": 5.956183,
     "end_time": "2024-09-12T13:31:24.258958",
     "exception": false,
     "start_time": "2024-09-12T13:31:18.302775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ec5cece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:31:24.286952Z",
     "iopub.status.busy": "2024-09-12T13:31:24.286636Z",
     "iopub.status.idle": "2024-09-12T13:31:24.297883Z",
     "shell.execute_reply": "2024-09-12T13:31:24.297216Z"
    },
    "papermill": {
     "duration": 0.027105,
     "end_time": "2024-09-12T13:31:24.299777",
     "exception": false,
     "start_time": "2024-09-12T13:31:24.272672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_path = \"/kaggle/input/corner-cases/corner_cases/unhealthy_2/\"\n",
    "save_path = \"/kaggle/working/gradcam/corner_cases/unhealthy_2/\"\n",
    "\n",
    "# Unhealthy\n",
    "original_label = \"Unhealthy\"\n",
    "list_of_paths = []\n",
    "list_of_names = []\n",
    "\n",
    "for file_name in os.listdir(temp_path):\n",
    "    list_of_paths.append(temp_path + file_name)\n",
    "    \n",
    "list_of_names = [os.path.splitext(f)[0] for f in os.listdir(temp_path) if os.path.isfile(os.path.join(temp_path, f))]\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1801b47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T13:31:24.325721Z",
     "iopub.status.busy": "2024-09-12T13:31:24.325411Z",
     "iopub.status.idle": "2024-09-12T13:31:32.452853Z",
     "shell.execute_reply": "2024-09-12T13:31:32.451964Z"
    },
    "papermill": {
     "duration": 8.142928,
     "end_time": "2024-09-12T13:31:32.455079",
     "exception": false,
     "start_time": "2024-09-12T13:31:24.312151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file_path in list_of_paths:\n",
    "    image_path = file_path\n",
    "    img = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    input_tensor = preprocess(pil_img).unsqueeze(0)\n",
    "    model.to('cuda')\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[model.effnet.features[-1][0]])\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor)\n",
    "    resized_cam = cv2.resize(grayscale_cam[0], (img.shape[1], img.shape[0]))\n",
    "    visualization = show_cam_on_image(img / 255.0, resized_cam, use_rgb=True)\n",
    "    \n",
    "    output = model(input_tensor.to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if int(predicted[0]) == 0:\n",
    "        predicted_label = \"Healthy\"\n",
    "    else:\n",
    "        predicted_label = \"Unhealthy\"\n",
    "\n",
    "    fig, ex = plt.subplots(1, 2, dpi = 150)\n",
    "    ex[0].imshow(visualization)\n",
    "    ex[0].set_title(\"Original: \" + original_label)\n",
    "    ex[1].imshow(img)\n",
    "    ex[1].set_title(\"Predicted: \" + predicted_label)\n",
    "    \n",
    "    plt.savefig(fname=(save_path+\"gradcam-\"+list_of_names[i]+\".jpg\"))\n",
    "    plt.close()\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5638824,
     "sourceId": 9310807,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5425207,
     "sourceId": 9346869,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5685641,
     "sourceId": 9373918,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 113200,
     "modelInstanceId": 88986,
     "sourceId": 106199,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 113200,
     "modelInstanceId": 88986,
     "sourceId": 108150,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 116454,
     "modelInstanceId": 92253,
     "sourceId": 110129,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.734875,
   "end_time": "2024-09-12T13:31:36.164177",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-12T13:28:28.429302",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
