# research-rop-classification
CNN Classifier for Recognizing Retinopathy of Premature

- Learning EfficientNet model from the Pytorch library – [rop-efficialnet-pytorch.ipynb]  
- Interpreting model using Grad-CAM – [rop-effnet-grad-cam (2).ipynb]


## Подсчет метрик для YOLO и EfficientNet

Загружаем две модели. Используем тестовый датасет с 80 изображениями. 

Демаем предсказание и записываем его в файл. 

Делаем посчет метрик:

### Precision, Recall, Accuracy

#### 1. **Precision** (Точность)
- **Определение:** Precision показывает, какая доля предсказанных положительных классов является правильной.
- **Формула:**
  
$$\text{Precision} = \frac{TP}{TP + FP}$$

  где:
  - **TP (True Positive)** — количество истинно положительных предсказаний,
  - **FP (False Positive)** — количество ложноположительных предсказаний.

#### 2. **Recall** (Полнота)
- **Определение:** Recall измеряет, какую долю всех истинных положительных классов модель смогла правильно классифицировать.
- **Формула:**
  
  $$\text{Recall} = \frac{TP}{TP + FN}$$
  где:
  - **TP (True Positive)** — количество истинно положительных предсказаний,
  - **FN (False Negative)** — количество ложноотрицательных предсказаний.

#### 3. **Accuracy** (Доля правильных ответов)
- **Определение:** Accuracy показывает, какую долю всех предсказаний модель сделала правильно.
- **Формула:**
  
  $$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$
  
  где:
  - **TP (True Positive)** — количество истинно положительных предсказаний,
  - **TN (True Negative)** — количество истинно отрицательных предсказаний,
  - **FP (False Positive)** — количество ложноположительных предсказаний,
  - **FN (False Negative)** — количество ложноотрицательных предсказаний.

### Матрица путаницы (Confusion Matrix)

**Матрица путаницы** — это таблица, которая используется для оценки качества работы классификационной модели. Она показывает, сколько предсказаний модель сделала правильно или ошибочно по каждому классу. В бинарной классификации матрица выглядит так:

|                    | **Предсказано: Позитив** | **Предсказано: Негатив** |
|--------------------|--------------------------|--------------------------|
| **Истинное: Позитив**  | True Positive (TP)        | False Negative (FN)       |
| **Истинное: Негатив**  | False Positive (FP)       | True Negative (TN)        |

- **TP (True Positive)** — количество правильно предсказанных положительных примеров.
- **TN (True Negative)** — количество правильно предсказанных отрицательных примеров.
- **FP (False Positive)** — количество неправильно предсказанных положительных примеров (ложноположительные).
- **FN (False Negative)** — количество неправильно предсказанных отрицательных примеров (ложноотрицательные).

Матрица путаницы позволяет вычислять метрики, такие как:
- **Precision (Точность)**
- **Recall (Полнота)**
- **Accuracy (Доля правильных ответов)**


### Доверительный интервал (Confidence Interval)

Вычисляем доверительный интервал 95% для уверенности модели в своих ответах.


