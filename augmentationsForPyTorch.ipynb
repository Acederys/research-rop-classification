{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "JUooieAYh_fW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cD9y5XlETG4L"
      },
      "outputs": [],
      "source": [
        "#Класс для создания датасета с увеличением количества примеров в 2 раза\n",
        "class DatasetWithAugmentations(Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.dataset = datasets.ImageFolder(root=root)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) * 2  # Удваиваем количество изображений\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = idx // 2  # Определяем индекс исходного изображения\n",
        "        image, label = self.dataset[original_idx]\n",
        "\n",
        "        # Применяем аугментацию дважды\n",
        "        augmented_image1 = self.transform(image)\n",
        "        augmented_image2 = self.transform(image)\n",
        "\n",
        "        if idx % 2 == 0:\n",
        "            return augmented_image1, label\n",
        "        else:\n",
        "            return augmented_image2, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_clahe(image):\n",
        "    # Преобразуем изображение из PIL в numpy array\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Применяем CLAHE к каждому каналу (RGB)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    image_np[:, :, 0] = clahe.apply(image_np[:, :, 0])\n",
        "    image_np[:, :, 1] = clahe.apply(image_np[:, :, 1])\n",
        "    image_np[:, :, 2] = clahe.apply(image_np[:, :, 2])\n",
        "\n",
        "    # Преобразуем обратно в PIL Image\n",
        "    image_pil = Image.fromarray(image_np)\n",
        "    return image_pil\n",
        "\n",
        "\n",
        "def transform(with_clahe, with_flip):\n",
        "    layers = []\n",
        "    # Определяем преобразования для изображений\n",
        "    if with_clahe:\n",
        "        layers.append(transforms.Lambda(apply_clahe))\n",
        "    layers.append(transforms.Resize((480, 640)))\n",
        "    if with_flip:\n",
        "        layers.append(transforms.RandomHorizontalFlip(p=0.5))\n",
        "        layers.append(transforms.RandomVerticalFlip(p=0.5))\n",
        "    # if with_rotation:\n",
        "    #     transforms.RandomRotation(degrees=(-90, 90)), # Пока убрал так как проблема с обрезанием картинки не решена\n",
        "    layers.append(transforms.ToTensor())\n",
        "    return transforms.Compose(layers)"
      ],
      "metadata": {
        "id": "ONNYxE64sK8Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функция для создания увеличенного в 2 раза датасета с аугментациями\n",
        "def CreateDatasetWithAugmentations(root, with_clahe, with_flip):\n",
        "    return DatasetWithAugmentations(\n",
        "        root=root,\n",
        "        transform=transform(with_clahe, with_flip)\n",
        "    )"
      ],
      "metadata": {
        "id": "cX5gzlxpTUKR"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}